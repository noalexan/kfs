### üèóÔ∏è Part 1: Foundations (Data & Memory Structures)

**Objectif :** D√©finir les structures de donn√©es statiques qui repr√©sentent un processus en m√©moire. Rien ne bouge encore, on d√©finit juste "ce qui existe".

#### 1. Le PCB (`struct task_struct`)
Le c≈ìur du syst√®me. voici un exemple de ce qu'il peu contenir :

* **Identit√© :** `pid_t pid`.
* **√âtat :** `enum process_state state` (NEW, RUNNING, WAITING, ZOMBIE).
* **Contexte CPU :** `uint32_t esp` (Le pointeur de pile noyau sauvegard√© lors d'un switch).
* **M√©moire :** `uint32_t cr3` (L'adresse physique du Page Directory du processus).
* **Maillage :** Pointeurs `struct task_struct *next` (pour la liste circulaire / ready queue).
* **Pile Noyau :** `void *kernel_stack` (Pointeur vers le bas de la pile allou√©e pour ce process).

#### 2. La "Trap Frame" (Register Snapshot)

**Objectif**
D√©finir la structure C (`struct trap_frame`) qui mappe exactement les donn√©es empil√©es lors d'une interruption. Elle servira d'interface entre l'Assembleur (ISR) et le C.

**Composition (du haut de la Stack vers le bas / Struct C)**

La structure doit contenir 3 couches distinctes :
1.  **Registres de Segments :** `ds`, `es`, `fs`, `gs` (sauvegard√©s manuellement).
2.  **Registres G√©n√©raux (GPRs) :** `edi`, `esi`, `ebp`, `esp`, `ebx`, `edx`, `ecx`, `eax` (correspondant √† l'instruction `pusha`).
3.  **Hardware Context :** `eip`, `cs`, `eflags`, + `user_esp`, `user_ss` (pouss√©s automatiquement par le CPU lors du changement de Ring).

#### 3. Memory Layout (Virtual Memory)

**Objectif**
D√©finir la cartographie de l'espace virtuel (4GB) propre √† chaque processus.

**A. L'Espace d'Adressage (The Map)**
Division stricte de la m√©moire virtuelle :
* **Kernel Space (Haut)** : Identique pour tous les processus. Inaccessible en Ring 3.
* **User Space (Bas)** : Zone priv√©e du processus.
    * *Code/Data* : D√©but de la m√©moire basse.
    * *Heap* : Grandit vers le haut.
    * *User Stack* : Part du haut de l'espace utilisateur et grandit vers le bas.

**B. Isolation (CR3)**
Chaque processus poss√®de sa propre copie du **Page Directory**.
* Il ne voit que *ses* donn√©es et le Kernel.
* Il est physiquement isol√© des autres processus.

**C. La Strat√©gie des Piles (Dual Stacks)**
Un processus a besoin de deux piles distinctes :
* **User Stack (Ring 3)** : Pour l'ex√©cution normale du programme.
* **Kernel Stack (Ring 0)** : Petite pile fixe (allou√©e par `kmalloc` dans le PCB) utilis√©e exclusivement lors des appels syst√®me et interruptions.

#### 4. Concurrency

Deux outils distincts pour prot√©ger le noyau contre la concurence, utilisables au choix selon le besoin :

**A. L'Interrupteur Global (`irq_disable` / `irq_enable`)**
* **C'est quoi ?** Le bouton "Stop tout". Il coupe les interruptions CPU (CLI).
* **√Ä quoi √ßa sert ?** Pour les sections ultra-critiques et courtes o√π le noyau ne doit *absolument pas* √™tre d√©rang√© (ex: pendant le changement de contexte).
* **M√©canisme :** Doit inclure un compteur pour pouvoir √™tre appel√© plusieurs fois de suite sans tout r√©activer trop t√¥t.

**B. Le Verrou d'Objet (`spinlock`)**
* **C'est quoi ?** Un cadenas qu'on attache √† une donn√©e pr√©cise (ex: `tty_lock`, `process_list_lock`).
* **√Ä quoi √ßa sert ?** Pour prot√©ger une ressource partag√©e. C'est plus propre : on sait *pourquoi* on bloque (on attend l'acc√®s au TTY).

#### 5. Le TSS (Task State Segment)

**Objectif**
Structure mat√©rielle x86 obligatoire pour g√©rer la transition de privil√®ge (Ring 3 vers Ring 0).

* **Strat√©gie "Single TSS" :** Nous n'utilisons pas le multit√¢che mat√©riel d'Intel. Une seule instance `TSS` est d√©clar√©e globalement pour tout le noyau.
* **R√¥le Unique :** Stocker le pointeur `ESP0`.
    * √Ä chaque `context_switch`, le noyau mettra √† jour ce champ `ESP0` dans le TSS avec l'adresse de la pile noyau du *nouveau* processus.
    * Lors d'une interruption, le CPU lit ce champ pour savoir o√π empiler les donn√©es en toute s√©curit√©.
* **GDT :** N√©cessite une entr√©e sp√©cifique dans la Global Descriptor Table.

#### 6. Le PID Manager (Pour la Part 1)
**Le Probl√®me :** Dans la struct PCB, tu as `pid_t pid`. Mais comment garantis-tu que chaque PID est unique, surtout apr√®s 10 000 cr√©ations/destructions de processus ? Un simple `++` finit par "wrap around" (revenir √† 0) et cr√©er des collisions.

**L'Ajout (Dans Part 1 - Foundations) :**
* **PID Allocator :** Un syst√®me simple (Bitmap ou Liste de PIDs libres) pour savoir quels ID sont disponibles.

---------------------------

### ‚öôÔ∏è Part 2: Execution (Lifecycle & Operations)

**Objectif :** D√©finir les m√©canismes de bas niveau permettant √† un processus de na√Ætre, de changer de contexte, et de mourir proprement.

#### 1. Context Switch (`switch_to`)
Le c≈ìur du multit√¢che. Une fonction purement assembleur.
* **Prototype :** `void switch_to(struct task_struct *prev, struct task_struct *next);`
* **M√©canisme (Stack Switching) :**
    1.  Sauvegarder les registres "Callee-Saved" (EBX, ESI, EDI, EBP) sur la stack de `prev`.
    2.  Sauvegarder `ESP` actuel dans `prev->esp`.
    3.  Charger `next->esp` dans le registre `ESP`.
    4.  **Crucial :** Mettre √† jour `g_tss.esp0` avec la nouvelle adresse de stack noyau (pour les futures interruptions).
    5.  Restaurer les registres "Callee-Saved" depuis la (nouvelle) stack.
    6.  `RET` (Le CPU d√©pile l'EIP de retour... qui appartient au nouveau processus !).

#### 2. Creation : Le clonage (`fork`)
La fonction la plus complexe √† impl√©menter.
* **Memory Ops :**
    * `kmalloc` d'un nouveau PCB.
    * Duplication du Page Directory (VMM).
    * Utilisation d'un system copy on write (attention au dirty cow)
* **Kernel Stack Crafting (La partie magique) :**
    * Il faut construire artificiellement la stack du fils.
    * Y placer une "Trap Frame" factice pour que, quand le scheduler le choisira, il "retombe" √† l'instruction suivant le fork.
    * Forcer la valeur de retour `EAX = 0` dans cette stack (pour que le fils sache qu'il est le fils).

### 2.5. Le Bootstrap du Premier Processus 
**Le Probl√®me :** `fork()` copie un processus existant. Mais comment na√Æt le **tout premier** processus (`init`) puisqu'il n'a pas de parent √† copier ?

**L'Ajout (Dans Part 2 - Execution) :**
* **Manual Crafting (Process 0/1) :** Une fonction sp√©ciale `init_process_creation()` qui :
    1.  Alloue un PCB √† la main.
    2.  Configure manuellement sa stack et ses registres.
    3.  Le place de force dans la `Ready Queue` pour lancer la machine.


#### 3. Loading : L'ex√©cution (`execve`)
* **R√¥le :** Remplacer l'image m√©moire du processus actuel par un nouveau programme (ELF).
* **√âtapes :**
    1.  Vider l'espace d'adressage actuel (unmap).
    2.  Parser le fichier ELF.
    3.  Mapper les segments (Code, Data) en m√©moire.
    4.  Allouer une nouvelle pile utilisateur et y copier les arguments (`argv`, `envp`).
    5.  Reset des registres (EIP = Entry Point du ELF).

#### 4. Termination : La mort (`exit` & `wait`)

Gestion de la fin de vie et de l'√©tat ZOMBIE.
* **`exit(int status)` :**
    * Lib√®re toute la m√©moire (VMM, User Stack, Heap).
    * Ferme les fichiers ouverts.
    * **NE LIB√àRE PAS** le PCB ni la Kernel Stack.
    * Passe l'√©tat √† `ZOMBIE`.
    * Envoie un signal (`SIGCHLD`) au parent.
    * Appelle `schedule()` (ne revient jamais).
* **`wait(int *status)` :**
    * Le parent se met en pause (WAITING) tant qu'il n'a pas de fils Zombie.
    * Si un fils est Zombie : R√©cup√®re le `status`, et appelle enfin `kfree(child_pcb)`.

#### 5. Orphan Management (Adoption)

Que se passe-t-il si le Parent meurt *avant* le Fils ?
* **Le probl√®me :** Si le fils fait `exit`, personne ne fera `wait`, donc il restera Zombie pour l'√©ternit√© (Memory Leak).
* **La solution (Reparenting) :** Lors du `exit()` d'un processus, s'il a des enfants, on change leur `parent_id` pour le mettre √† `1` (Processus `init`). `init` a pour seule mission de faire des `wait()` en boucle pour nettoyer les orphelins.

#### 6. Syst√®me de Signaux

**Objectif**
G√©rer les interruptions asynchrones en d√©tournant temporairement l'ex√©cution du processus.

**A. Les Donn√©es**
Le PCB doit simplement savoir :
1.  Quels signaux sont arriv√©s (Bitmap `pending`).
2.  Comment les traiter (Tableau d'actions : Tuer, Ignorer, ou Fonction Perso).

**B. Le M√©canisme : "Le D√©tournement"**
Au moment de rendre la main au processus, si un signal est pr√©sent :
1.  Le noyau **sauvegarde** l'√©tat du processus sur sa propre pile.
2.  Il **force** le CPU √† ex√©cuter la fonction du signal (Handler) au lieu de continuer le programme.

**C. Le Retour**
Une fois la fonction du signal termin√©e, le processus utilise un m√©canisme de "Trampoline" (Syscall `sigreturn`) pour **restaurer** ses registres sauvegard√©s et reprendre son travail exactement l√† o√π il s'√©tait arr√™t√©.


---------------------------

### ‚è±Ô∏è Part 3: Scheduling & Dispatching

**Objectif :** D√©finir "Qui" a le droit d'utiliser le CPU, "Quand", et g√©rer les risques li√©s √† l'interruption brutale des processus.

#### 1. Core Architecture (Queues & States)
* **State Machine :** Impl√©mentation de l'enum `process_state`.
    
    * **New** : En cr√©ation.
    * **Running** : Sur le CPU.
    * **Waiting** : Attend une ressource (Clavier, Disque).
    * **Ready** : Attend le CPU.
    * **Terminated** : Fini.
* **Dynamic Queues :**
    * Utilisation de listes cha√Æn√©es pour cr√©er dynamiquement des files d'attente pour les futurs drivers (Keyboard queue, Disk queue, etc.).

### 1.5. La T√¢che "Idle" (Pour la Part 3)
**Le Probl√®me :** Que se passe-t-il si la `Ready Queue` est vide ? (Ex: tous les processus attendent une I/O clavier ou disque).
Si `schedule()` ne trouve personne √† ex√©cuter, il retourne `NULL` -> `switch_to(current, NULL)` -> **Crash Kernel Panic**.

**L'Ajout (Dans Part 3 - Scheduling) :**
* **The Idle Task (PID 0) :** Un processus sp√©cial, cr√©√© au d√©marrage, qui a la priorit√© la plus basse possible.
* **R√¥le :** Il ne fait qu'une boucle infinie contenant l'instruction `hlt` (pour √©conomiser l'√©nergie du CPU).
* **Logique :** Il est toujours `READY`. Si le Scheduler ne trouve personne d'autre, il choisit *toujours* Idle.

#### 2. Concurrency & Preemption Challenges
L'ordonnancement pr√©emptif introduit le risque critique de **Race Condition**.

* **Le Probl√®me :** Deux processus (ou un processus et une interruption) tentent de modifier la m√™me structure de donn√©es (ex: la Ready Queue) en m√™me temps.
* **La Solution (Critical Sections) :**
    * **Syscalls :** Doivent garantir la coh√©rence des donn√©es avant de rendre la main.
    * **ISR & Kernel Code :** Toute manipulation de structure partag√©e doit √™tre prot√©g√©e.
    * **M√©canisme :** Utiliser un des mecanisme fait dans fondation donc spin lock ou deactivation des interrupt

#### 3. The Dispatcher
C'est le module de bas niveau qui ex√©cute la d√©cision du scheduler. Il doit √™tre optimis√© pour r√©duire la **Dispatch Latency**.
**Fonctions cl√©s :**
1.  **Context Switch :** Sauvegarde l'√©tat A, charge l'√©tat B.
2.  **Mode Switch :** Transition Ring 0 $\to$ Ring 3.
3.  **Restore EIP :** Saut vers la prochaine instruction du programme utilisateur.

#### 4. Scheduling Algorithms 
Ordre d'impl√©mentation pour le d√©veloppement :
1.  **FCFS (First-Come, First-Served)** : Simple file d'attente. Le processus doit `yield` volontairement. (Dev/Debug only).
2.  **Round Robin (RR) - *Objectif V1*** : FCFS + Timer Interrupt (Quantum de temps). C'est le standard des syst√®mes √† temps partag√©.
3.  **MLFQ (Multi-Level Feedback Queue) - *Objectif V2*** : Files multiples avec priorit√©s dynamiques (favorise les I/O bound, punit les CPU bound).
